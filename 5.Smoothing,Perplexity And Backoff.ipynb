{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "P <sub>Add-k</sub>(w<sub>i-1</sub>|w<sub>i</sub>) =c(wi-1;wi)+k/(c(wi-1)+kV) where V is the number of tokens\n",
    "<br/>\n",
    "Kneser- Ney Smoothing\n",
    "P<sub>KN</sub>(wi|wi-1) =max(c(w<sub>i-1</sub>;w<sub>i</sub>)-d;0)/c(w<sub>i</sub>-1) + d/c(w<sub>i-1</sub>)*P<sub>continuation</sub>(w<sub>i</sub>)\n",
    "<br/>\n",
    "P<sub>continuation</sub>(w<sub>i</sub>)=|{w<sub>i-1</sub> : c(w<sub>i-1</sub>,w)>0}|/ |{(w<sub>j-1</sub>,w<sub>j</sub>) : c(w<sub>j-1</sub>,w<sub>j</sub>)>0}|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BiGram -> Without Smoothing, Add 1, Add 5, Kneser-Ney\n",
      "(u'her', u'taste') -> 0.003410 0.000119 0.000044 0.002607\n",
      "(u'form', u'or') -> 0.111111 0.000049 0.000029 0.001067\n",
      "(u'every', u'kind') -> 0.004902 0.000049 0.000029 0.000071\n",
      "(u'altogether', u'affectionate') -> 0.062500 0.000049 0.000029 0.000052\n",
      "(u'pity', u'me') -> 0.307692 0.000123 0.000044 0.231463\n",
      "(u'indifferent', u'appear') -> 0.076923 0.000049 0.000029 0.000116\n",
      "(u'still', u'at') -> 0.042553 0.000074 0.000034 0.023363\n",
      "(u'Mr.', u'seems') -> 0.001789 0.000048 0.000029 0.000019\n",
      "(u'Cole', u'a') -> 0.037037 0.000049 0.000029 0.003324\n",
      "(u'He', u'trifles') -> 0.004425 0.000049 0.000029 0.000008\n",
      "(u'adversary', u'self-approbation') -> 1.000000 0.000049 0.000029 0.000010\n",
      "(u'pursuit', u'of') -> 0.500000 0.000049 0.000029 0.008243\n",
      "(u'want', u'you') -> 0.041667 0.000074 0.000034 0.021866\n",
      "(u'think', u'are') -> 0.004926 0.000049 0.000029 0.000332\n",
      "(u'he', u'entered') -> 0.001493 0.000048 0.000029 0.000033\n",
      "(u'too', u'scrupulous') -> 0.008065 0.000049 0.000029 0.000005\n",
      "(u'of', u'matrimony') -> 0.000473 0.000047 0.000029 0.000008\n",
      "(u'be', u'fit') -> 0.001047 0.000048 0.000029 0.000033\n",
      "(u'his', u'old') -> 0.001949 0.000049 0.000029 0.000146\n",
      "(u'They', u'came') -> 0.012048 0.000049 0.000029 0.000209\n",
      "(u'sky', u'companion') -> 1.000000 0.000049 0.000029 0.000125\n",
      "(u'at', u'times') -> 0.006085 0.000097 0.000039 0.004086\n",
      "(u'.', u'Five') -> 0.000313 0.000046 0.000029 0.000001\n",
      "(u'slight', u'fit') -> 0.142857 0.000049 0.000029 0.000083\n",
      "(u'and', u'maintained') -> 0.000433 0.000046 0.000029 0.000009\n",
      "(u'with', u'full') -> 0.001610 0.000048 0.000029 0.000075\n",
      "(u'were', u'obliged') -> 0.006849 0.000073 0.000034 0.003542\n",
      "(u'being', u'--') -> 0.005587 0.000049 0.000029 0.004588\n",
      "(u'particularly', u'niece') -> 0.041667 0.000049 0.000029 0.000046\n",
      "(u',', u'gentlemanlike') -> 0.000336 0.000064 0.000033 0.000172\n",
      "(u'instead', u'Ireland') -> 0.066667 0.000049 0.000029 0.000034\n",
      "(u'commonplace', u'situation') -> 0.333333 0.000049 0.000029 0.000230\n",
      "(u'``', u'paper') -> 0.001129 0.000048 0.000029 0.000021\n",
      "(u'hazard', u'disgustingly') -> 1.000000 0.000049 0.000029 0.000021\n",
      "(u'ask', u'her') -> 0.260870 0.000172 0.000054 0.219397\n",
      "(u'now', u'that') -> 0.020548 0.000098 0.000039 0.014887\n",
      "(u'.', u'very') -> 0.000625 0.000068 0.000034 0.000478\n",
      "(u'wishes', u'which') -> 0.100000 0.000049 0.000029 0.000840\n",
      "(u'a', u'glimpse') -> 0.000630 0.000047 0.000029 0.000008\n",
      "(u'of', u'expectation') -> 0.000473 0.000047 0.000029 0.000021\n",
      "(u'Mr.', u'Taylor') -> 0.001789 0.000048 0.000029 0.000043\n",
      "(u'her', u'shawl') -> 0.001705 0.000072 0.000034 0.000856\n",
      "(u'new', u'drills') -> 0.066667 0.000049 0.000029 0.000010\n",
      "(u'tea', u'with') -> 0.090909 0.000049 0.000029 0.001571\n",
      "(u'odd', u'though') -> 0.076923 0.000049 0.000029 0.000079\n",
      "(u'be', u'beautiful') -> 0.001047 0.000048 0.000029 0.000045\n",
      "(u'allowed', u'merely') -> 0.043478 0.000049 0.000029 0.000068\n",
      "(u'kindness', u'and') -> 0.142857 0.000074 0.000034 0.075110\n",
      "(u'changed', u'also') -> 0.333333 0.000049 0.000029 0.000094\n",
      "(u'overcome', u'.') -> 0.400000 0.000074 0.000034 0.209475\n",
      "(u'These', u'were') -> 0.125000 0.000049 0.000029 0.001132\n",
      "(u'kept', u';') -> 0.090909 0.000049 0.000029 0.006346\n",
      "(u';', u'escape') -> 0.000814 0.000048 0.000029 0.000008\n",
      "(u'account.', u'--') -> 1.000000 0.000098 0.000039 0.669133\n",
      "(u'of', u'penance') -> 0.000473 0.000047 0.000029 0.000005\n",
      "(u'And', u'Mr.') -> 0.017544 0.000073 0.000034 0.009667\n",
      "(u'been', u'correct.') -> 0.002571 0.000049 0.000029 0.000005\n",
      "(u'his', u'arm') -> 0.003899 0.000073 0.000034 0.001982\n",
      "(u'better', u'go') -> 0.047619 0.000123 0.000044 0.035873\n",
      "(u'gentle', u'encouragement') -> 0.166667 0.000049 0.000029 0.000125\n",
      "(u'have', u'made') -> 0.008982 0.000169 0.000054 0.007646\n",
      "(u'doating', u'on') -> 0.500000 0.000049 0.000029 0.002087\n",
      "(u'be', u'occupied') -> 0.001047 0.000048 0.000029 0.000033\n",
      "(u'gone', u'when') -> 0.022727 0.000049 0.000029 0.000313\n",
      "(u'be', u'better') -> 0.003141 0.000096 0.000039 0.002271\n",
      "(u'attachment', u'his') -> 0.037037 0.000049 0.000029 0.001064\n",
      "(u'somewhat', u'sudden') -> 1.000000 0.000049 0.000029 0.000104\n",
      "(u'as', u'trifles') -> 0.001383 0.000048 0.000029 0.000005\n",
      "(u'his', u'wishes') -> 0.001949 0.000049 0.000029 0.000043\n",
      "(u'the', u'offer') -> 0.001229 0.000093 0.000039 0.000849\n",
      "(u'my', u'power') -> 0.009740 0.000097 0.000039 0.006573\n",
      "(u'smiles', u'must') -> 0.166667 0.000049 0.000029 0.000563\n",
      "(u'or', u'composure') -> 0.004274 0.000049 0.000029 0.000023\n",
      "(u'whatever', u'he') -> 0.125000 0.000049 0.000029 0.001596\n",
      "(u'that', u'Harriet') -> 0.012443 0.000288 0.000078 0.011542\n",
      "(u',', u'making') -> 0.000672 0.000107 0.000043 0.000525\n",
      "(u'--', u'never') -> 0.001890 0.000095 0.000039 0.001417\n",
      "(u'satisfied', u'should') -> 0.028571 0.000049 0.000029 0.000514\n",
      "(u'been', u'possible') -> 0.002571 0.000049 0.000029 0.000094\n",
      "(u'company', u'Mr.') -> 0.086957 0.000074 0.000034 0.045099\n",
      "(u'more', u'about') -> 0.008299 0.000073 0.000034 0.004541\n",
      "(u'perfectly', u'--') -> 0.034483 0.000049 0.000029 0.005357\n",
      "(u'caro', u'sposo') -> 0.500000 0.000049 0.000029 0.000010\n",
      "(u'you', u'sing') -> 0.001215 0.000048 0.000029 0.000003\n",
      "(u'he', u'grew') -> 0.001493 0.000048 0.000029 0.000008\n",
      "(u'would', u'offend') -> 0.002513 0.000049 0.000029 0.000003\n",
      "(u'manners', u'did') -> 0.035714 0.000049 0.000029 0.000415\n",
      "(u'are', u'got') -> 0.004219 0.000049 0.000029 0.000075\n",
      "(u'are', u'pretty') -> 0.008439 0.000073 0.000034 0.004369\n",
      "(u'kindly', u',') -> 0.500000 0.000098 0.000039 0.345006\n",
      "(u'spirits', u'.') -> 0.029412 0.000049 0.000029 0.006270\n",
      "(u'great', u'had') -> 0.007519 0.000049 0.000029 0.000966\n",
      "(u'from', u'own') -> 0.003861 0.000049 0.000029 0.000109\n",
      "(u'liberty', u'of') -> 0.200000 0.000049 0.000029 0.008243\n",
      "(u'she', u'betrayed') -> 0.001136 0.000048 0.000029 0.000002\n",
      "(u'returning', u'your') -> 0.090909 0.000049 0.000029 0.000702\n",
      "(u'wanting', u'to') -> 0.450000 0.000245 0.000069 0.404236\n",
      "(u'some', u'body') -> 0.015748 0.000073 0.000034 0.008035\n",
      "(u'thing', u'than') -> 0.010256 0.000073 0.000034 0.005596\n",
      "(u'when', u'influence') -> 0.006579 0.000049 0.000029 0.000038\n",
      "(u'full', u'comfort') -> 0.034483 0.000049 0.000029 0.000199\n",
      "(u'of', u'head') -> 0.000473 0.000047 0.000029 0.000032\n",
      "(u'and', u'he') -> 0.017741 0.000976 0.000223 0.017785\n",
      "(u'ridiculous', u',') -> 1.000000 0.000049 0.000029 0.017509\n",
      "(u'long', u'we') -> 0.014286 0.000049 0.000029 0.000309\n",
      "(u'besides', u'his') -> 0.333333 0.000049 0.000029 0.001795\n",
      "(u'her', u'last') -> 0.001705 0.000072 0.000034 0.000947\n",
      "(u'much', u'as') -> 0.063492 0.000415 0.000103 0.060834\n",
      "(u'any', u'more') -> 0.006135 0.000073 0.000034 0.003505\n",
      "(u'his', u'request') -> 0.001949 0.000049 0.000029 0.000011\n",
      "(u'know', u'at') -> 0.012346 0.000073 0.000034 0.006860\n",
      "(u'School', u'morality') -> 1.000000 0.000049 0.000029 0.000010\n",
      "(u'not', u'meet') -> 0.000861 0.000048 0.000029 0.000015\n",
      "(u'life', u'would') -> 0.025000 0.000049 0.000029 0.000750\n",
      "(u'messages', u'failing') -> 1.000000 0.000049 0.000029 0.000010\n",
      "(u'--', u'quite') -> 0.004411 0.000189 0.000058 0.003887\n",
      "(u'reserve', u'on') -> 0.250000 0.000049 0.000029 0.002087\n",
      "(u'(', u'Harriet') -> 0.015873 0.000049 0.000029 0.000717\n",
      "(u'a', u'society') -> 0.001259 0.000071 0.000034 0.000713\n",
      "(u\"'s\", u'meditated') -> 0.002232 0.000049 0.000029 0.000012\n",
      "(u'being', u'present') -> 0.011173 0.000073 0.000034 0.005768\n",
      "(u'tree', u',') -> 0.333333 0.000049 0.000029 0.017509\n",
      "(u'very', u'kindly') -> 0.001799 0.000048 0.000029 0.000023\n",
      "(u'and', u'well') -> 0.001298 0.000093 0.000039 0.001055\n",
      "(u'appeared', u'absolutely') -> 0.043478 0.000049 0.000029 0.000082\n",
      "(u'strikes', u'me') -> 1.000000 0.000049 0.000029 0.001127\n",
      "(u'Mr.', u'Mr.') -> 0.007156 0.000121 0.000044 0.005770\n",
      "(u'distinctly', u'forward.') -> 0.200000 0.000049 0.000029 0.000010\n",
      "(u'soon', u'away') -> 0.009259 0.000049 0.000029 0.000259\n",
      "(u'myself', u'too') -> 0.021277 0.000049 0.000029 0.000368\n",
      "(u'!', u'My') -> 0.001876 0.000048 0.000029 0.000014\n",
      "(u'herself', u'before') -> 0.007634 0.000049 0.000029 0.000326\n",
      "(u'letters', u'with') -> 0.047619 0.000049 0.000029 0.001920\n",
      "(u'usual.', u'distinguished') -> 1.000000 0.000049 0.000029 0.000031\n",
      "(u'being', u'affected') -> 0.005587 0.000049 0.000029 0.000019\n",
      "(u'Jane', u'will') -> 0.020979 0.000098 0.000039 0.014210\n",
      "(u'them', u'through') -> 0.004255 0.000049 0.000029 0.000085\n",
      "(u'disappointment', u'?') -> 0.111111 0.000049 0.000029 0.001660\n",
      "(u'that', u'my') -> 0.006787 0.000168 0.000054 0.005841\n",
      "(u'no', u'knowledge') -> 0.003289 0.000049 0.000029 0.000051\n",
      "(u'build', u'upon') -> 1.000000 0.000049 0.000029 0.000355\n",
      "(u'husbands', u',') -> 1.000000 0.000049 0.000029 0.017509\n",
      "(u'It', u'can') -> 0.010695 0.000073 0.000034 0.005458\n",
      "(u'Always', u'deceived') -> 0.500000 0.000049 0.000029 0.000052\n",
      "(u'told', u'by') -> 0.027778 0.000049 0.000029 0.000609\n",
      "(u'your', u'--') -> 0.006993 0.000049 0.000029 0.005277\n",
      "(u'attestation', u'that') -> 1.000000 0.000049 0.000029 0.002755\n",
      "(u'fancy', u'Mr.') -> 0.055556 0.000049 0.000029 0.001635\n",
      "(u'Goddard', u'to') -> 0.043478 0.000049 0.000029 0.006263\n",
      "(u'towards', u'Mr.') -> 0.029412 0.000049 0.000029 0.001154\n",
      "(u'paused', u'a') -> 1.000000 0.000049 0.000029 0.003903\n",
      "(u'say', u'--') -> 0.024242 0.000122 0.000044 0.020513\n",
      "(u'fever', u'to') -> 0.333333 0.000049 0.000029 0.008473\n",
      "(u'add', u'his') -> 0.090909 0.000049 0.000029 0.001468\n",
      "(u'curious', u'to') -> 0.500000 0.000049 0.000029 0.008473\n",
      "(u'was', u'safe') -> 0.001675 0.000072 0.000034 0.000858\n",
      "(u'had', u'formerly') -> 0.001224 0.000048 0.000029 0.000003\n",
      "(u'wants', u'to') -> 0.500000 0.000074 0.000034 0.256355\n",
      "(u'sad', u'uncertainty') -> 0.083333 0.000049 0.000029 0.000026\n",
      "(u'a', u'leave') -> 0.000630 0.000047 0.000029 0.000061\n",
      "(u'Poor', u'old') -> 0.133333 0.000074 0.000034 0.066873\n",
      "(u'old', u\"''\") -> 0.020000 0.000049 0.000029 0.000375\n",
      "(u'it', u'into') -> 0.002868 0.000096 0.000039 0.002034\n",
      "(u\"'s\", u'comforts') -> 0.002232 0.000049 0.000029 0.000031\n",
      "(u'was', u'really') -> 0.006700 0.000215 0.000063 0.005975\n",
      "(u'learn', u'to') -> 0.750000 0.000098 0.000039 0.504236\n",
      "(u'had', u'led') -> 0.004896 0.000120 0.000044 0.003693\n",
      "(u'satisfied', u'Mr.') -> 0.028571 0.000049 0.000029 0.001401\n",
      "(u'stray', u'letter') -> 1.000000 0.000049 0.000029 0.000230\n",
      "(u'want', u'ribbon') -> 0.020833 0.000049 0.000029 0.000016\n",
      "(u'as', u'agitated') -> 0.001383 0.000048 0.000029 0.000008\n",
      "(u'as', u'Mrs.') -> 0.012448 0.000241 0.000069 0.011271\n",
      "(u'representing', u'to') -> 0.333333 0.000049 0.000029 0.008473\n",
      "(u'loves', u'Nonsense') -> 0.200000 0.000049 0.000029 0.000025\n",
      "(u'probability', u'unless') -> 0.142857 0.000049 0.000029 0.000052\n",
      "(u'love', u'eye') -> 0.015385 0.000049 0.000029 0.000069\n",
      "(u'most', u'speaking') -> 0.008547 0.000049 0.000029 0.000121\n",
      "(u'exploring', u'to') -> 0.500000 0.000049 0.000029 0.008473\n",
      "(u'shall', u'?') -> 0.009346 0.000049 0.000029 0.000803\n",
      "(u'heart', u'was') -> 0.103448 0.000098 0.000039 0.070232\n",
      "(u'commit', u'yourself') -> 1.000000 0.000049 0.000029 0.000250\n",
      "(u'houseroom', u'till') -> 1.000000 0.000049 0.000029 0.000313\n",
      "(u'made', u'the') -> 0.105263 0.000270 0.000074 0.096497\n",
      "(u'Hartfield', u'was') -> 0.013889 0.000049 0.000029 0.000990\n",
      "(u'without', u'suspicion') -> 0.011628 0.000049 0.000029 0.000040\n",
      "(u'kind', u'you') -> 0.027778 0.000049 0.000029 0.001263\n",
      "(u'cautiousness', u'manner') -> 1.000000 0.000049 0.000029 0.000303\n",
      "(u'seems', u'a') -> 0.266667 0.000123 0.000044 0.202862\n",
      "(u'when', u'the') -> 0.072368 0.000294 0.000079 0.067068\n",
      "(u'eligible', u',') -> 1.000000 0.000049 0.000029 0.017509\n",
      "(u\"'s\", u'wretchedness') -> 0.002232 0.000049 0.000029 0.000018\n",
      "(u'the', u'chosen') -> 0.001229 0.000093 0.000039 0.000834\n",
      "(u'injured', u'by') -> 0.500000 0.000049 0.000029 0.001826\n",
      "(u'be', u'understood') -> 0.003141 0.000096 0.000039 0.002131\n",
      "(u'run', u'such') -> 0.111111 0.000049 0.000029 0.000641\n",
      "(u'.', u'Mr.') -> 0.017812 0.001321 0.000300 0.017739\n",
      "(u'by', u'making') -> 0.003333 0.000049 0.000029 0.000071\n",
      "(u'not', u'offended') -> 0.000861 0.000048 0.000029 0.000006\n",
      "(u'hard', u',') -> 0.111111 0.000049 0.000029 0.015564\n",
      "(u'She', u'touched') -> 0.003460 0.000049 0.000029 0.000013\n",
      "(u'wrapt', u'sky') -> 1.000000 0.000049 0.000029 0.000010\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "token=nltk.word_tokenize(nltk.corpus.gutenberg.raw(nltk.corpus.gutenberg.fileids()[0]))\n",
    "counting=[]\n",
    "#Removing Comma, ...\n",
    "for item in token:\n",
    "     if(item==u',' or u'.' or u'--' or u'!'):\n",
    "         token.remove(item)    \n",
    "bigrams=list(ngrams(token,2))\n",
    "bigramSet= set(bigrams)\n",
    "i=0\n",
    "t1=[]\n",
    "t2=[]\n",
    "#Displayed only 200 entries for fast processing\n",
    "for item in bigramSet:\n",
    "    if i>200:\n",
    "        break;\n",
    "    counting.append(bigrams.count(item) + 1)\n",
    "    if (counting[i] -2)<0:\n",
    "        t1.append(0)\n",
    "    else:\n",
    "        t1.append((counting[i]-2)/float(token.count(item[0])))\n",
    "    n1=0\n",
    "    n2=0\n",
    "    for term in bigramSet:\n",
    "        if(term[0]==item[0]):\n",
    "            n1=n1+1\n",
    "        if(term[1]==item[1]):\n",
    "            n2=n2+1\n",
    "    t2.append(n1*n2/float(token.count(item[0])*len(bigrams)))\n",
    "    i=i+1\n",
    "i=0\n",
    "print \"BiGram -> Without Smoothing, Add 1, Add 5, Kneser-Ney\"\n",
    "for item in bigramSet:\n",
    "    if i>200:\n",
    "        break;\n",
    "    print \"%s -> %f %f %f %f\" %(item,(counting[i]-1)/float(token.count(item[0])),counting[i]/float((token.count(item[0])+ len(bigramSet))),(counting[i] +4)/float((token.count(item[0])+ 5*len(bigramSet))),t1[i]+t2[i])\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "Perplexity = P(w1w2 : : :wN) <sup>-1/N</sup>\n",
    "<br/>\n",
    "For Unigram Model: P(w<sub>i</sub>)= count(w<sub>i</sub>)/No. of tokens\n",
    "<br/>\n",
    "For Bigram Model: P(w<sub>i</sub>|w<sub>i-1</sub>)= count(w<sub>i-1</sub>w<sub>i</sub>)/count(w<sub>i-1</sub>)\n",
    "<br/>\n",
    "For Trigram Model: P(w<sub>i</sub>|w<sub>i-2</sub>w<sub>i-1</sub>)= count(w<sub>i-2</sub>w<sub>i-1</sub>w<sub>i</sub>)/count(w<sub>i-2</sub>w<sub>i-1</sub>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram perplexity = 440.086258\n",
      "Bigram perplexity = 5.018932\n",
      "Trigram perplexity = 2.845053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "token=nltk.word_tokenize(nltk.corpus.gutenberg.raw(nltk.corpus.gutenberg.fileids()[0]))\n",
    "#Removing Comma, ...\n",
    "for item in token:\n",
    "     if(item==u',' or u'.' or u'--' or u'!'):\n",
    "         token.remove(item)    \n",
    "bigrams=list(ngrams(token,2))\n",
    "bigramSet= set(bigrams)\n",
    "trigrams=list(ngrams(token,3))\n",
    "trigramSet= set(trigrams)\n",
    "perplexity1=float(1.0)\n",
    "n= len (token)\n",
    "i=0\n",
    "for item in token:\n",
    "    perplexity1=perplexity1*((1/float(token.count(item)))**(1./n))\n",
    "    i=i+1\n",
    "perplexity1=(perplexity1)*len(token)\n",
    "print \"Unigram perplexity = %f\" %(perplexity1)\n",
    "perplexity2=1.0\n",
    "i=0\n",
    "k=0\n",
    "for item in bigramSet:\n",
    "    perplexity2= perplexity2*(((1/float(bigrams.count(item)))*token.count(item[0]))**(1./n))\n",
    "    i=i+1\n",
    "print \"Bigram perplexity = %f\" %(perplexity2)\n",
    "perplexity3=1.0\n",
    "i=0\n",
    "for item in trigramSet:\n",
    "       perplexity3=perplexity3*(((1/float(trigrams.count(item)))*bigrams.count(item[0:2]))**(1./n))\n",
    "       i=i+1\n",
    "#perplexity3 = perplexity3)) * ((n+k)/n)\n",
    "print \"Trigram perplexity = %f\" %(perplexity3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Backoff\n",
    "P(w<sub>i</sub>|w<sub>i-2</sub>w<sub>i-1</sub>)= <br/>\n",
    "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P(w<sub>i</sub>|w<sub>i-2</sub>w<sub>i-1</sub>) if count(w<sub>i-2</sub>w<sub>i-1</sub>w<sub>i</sub>)>0<br/>\n",
    "                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lambda;1P(w<sub>i</sub>|w<sub>i-1</sub>) if count(w<sub>i-2</sub>w<sub>i-1</sub>w<sub>i</sub>)>0 and count(w<sub>i-1</sub>w<sub>i-1</sub>)>0<br/>\n",
    "                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lambda;2P(w<sub>i</sub>)\n",
    " <br/>\n",
    " Considering an example with 5 strings 1)\"impose directed misfortunes\" 2) \"find out why\" 3) \"I used to\" 4) \"it was before\" 5) \"lets do it\" with &lambda;1 and &lambda;2 values assumed to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('find', 'out', 'why')\n",
      "Prob with unigram= 0.000115\n",
      "('impose', 'directed', 'misfortunes')\n",
      "Prob with trigram = 1.000000\n",
      "('I', 'used', 'to')\n",
      "Prob with trigram = 0.142857\n",
      "('it', 'was', 'before')\n",
      "Prob with trigram = 0.166667\n",
      "('lets', 'do', 'it')\n",
      "Prob with bigram= 0.028470\n"
     ]
    }
   ],
   "source": [
    "str= {(\"impose\",\"directed\",\"misfortunes\"),(\"find\", \"out\", \"why\"),(\"I\",\"used\",\"to\"),(\"it\",\"was\",\"before\"),(\"lets\",\"do\",\"it\")}\n",
    "for item in str:\n",
    "   print item\n",
    "   if trigrams.count(item)>0:\n",
    "      print \"Prob with trigram = %f\" %(trigrams.count(item)/float(bigrams.count(item[1:3])))\n",
    "   else:\n",
    "      if bigrams.count(item[1:3])>0:\n",
    "        print \"Prob with bigram= %f\" %(bigrams.count(item[1:3])/float(token.count(item[1])))\n",
    "      else:\n",
    "        print \"Prob with unigram= %f\" %(token.count(item[2])/float(len(token)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Developer - Mayank Bhasin<br>\n",
    "Email - mayankbhasin@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
